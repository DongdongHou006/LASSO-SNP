{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADMM adaptive lasso using ProximalOperators with line and golden section search\n",
    "# Automatic tuning of learning rate and regularization parameter\n",
    "# This code only only changes the ratio between test data and train data, and changes the input file\n",
    "# The original source code from https://github.com/patwa67/AUTALASSO\n",
    "\n",
    "using ProximalOperators\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gss_opt (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Golden section search to optimize lambda\n",
    "function gss_opt(alam, blam, tolgss, Xtesthot, ytest,abscovinv,maxnorm)\n",
    "  lama =alam*maxnorm # Lower lambda\n",
    "  lamb =blam*maxnorm # Higher lambda\n",
    "  gr = (sqrt(5.0) + 1.0) / 2.0 # Golden section ratio\n",
    "  toladmm = 1e-4 # Convergence tolerance for ADMM\n",
    "  fc = lasso_admm(Xtrainhot, ytrain, lama, zero(Xtrainhot[1,:]),zero(Xtrainhot[1,:]),f, abscovinv,toladmm)\n",
    "  lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "  fd = lasso_admm(Xtrainhot, ytrain, lamb, zero(Xtrainhot[1,:]),zero(Xtrainhot[1,:]),f, abscovinv,toladmm)\n",
    "  lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "  iter = 2\n",
    "  meanlam = zero(1.0:100.0)\n",
    "  #meanlam[iter] = (lama+lamb)/2\n",
    "  meanloss = zero(1.0:100.0)\n",
    "  #meanloss[1] = max(lossc,lossd)\n",
    "  #meanloss[iter] = (lossc+lossd)/2\n",
    "  lamc = lamb - (lamb - lama) / gr\n",
    "  lamd = lama + (lamb - lama) / gr\n",
    "  println(\"lossc =$lossc\")\n",
    "  println(\"lossd =$lossd\")\n",
    "  println(\"lambdaa =$lama\")\n",
    "  println(\"lambdab =$lamb\")\n",
    "  println(\"lambdac =$lamc\")\n",
    "  println(\"lambdad =$lamd\")\n",
    "  iter = 2\n",
    "  nodrun = 0\n",
    "  while abs(lamc - lamd)/((lamc + lamd)/2.0) > tolgss # Run GSS until convergence\n",
    "    iter = iter+1\n",
    "    if iter == 3\n",
    "    fc = lasso_admm(Xtrainhot, ytrain, lamc, fc[1],fc[2],f, abscovinv,toladmm)\n",
    "    lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "    fd = lasso_admm(Xtrainhot, ytrain, lamd, fd[1],fd[2],f, abscovinv,toladmm)\n",
    "    lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "    else\n",
    "    if nodrun==1\n",
    "    fc = lasso_admm(Xtrainhot, ytrain, lamc, fc[1],fc[2],f, abscovinv,toladmm)\n",
    "    lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "    else\n",
    "    fd = lasso_admm(Xtrainhot, ytrain, lamd, fd[1],fd[2],f, abscovinv,toladmm)\n",
    "    lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "    end\n",
    "    end\n",
    "    meanlam[iter] = (lamc+lamd)/2.0\n",
    "    meanloss[iter] = (lossc+lossd)/2.0\n",
    "    # Stop GSS if test MSE is increased two consecutive iterations\n",
    "    if (meanloss[iter] > meanloss[iter-1])&&(meanloss[iter-1] > meanloss[iter-2])\n",
    "      break\n",
    "    end\n",
    "    if lossc < lossd\n",
    "      lamb = lamd\n",
    "      fd=fc\n",
    "      lossd=lossc\n",
    "      nodrun=1\n",
    "    else\n",
    "      lama = lamc\n",
    "      fc=fd\n",
    "      lossc=lossd\n",
    "      nodrun=0\n",
    "    end\n",
    "    lamc = lamb - (lamb - lama) / gr\n",
    "    lamd = lama + (lamb - lama) / gr\n",
    "    #println(\"lossc =$lossc\")\n",
    "    #println(\"lossd =$lossd\")\n",
    "    println(\"lambdac =$lamc\")\n",
    "    println(\"lambdad =$lamd\")\n",
    "  end\n",
    "  # Final ADMM for optimized lambda\n",
    "  lamopt = meanlam[iter-2]\n",
    "  fmean1 = (fc[1]+fd[1])/2.0\n",
    "  fmean2 = (fc[2]+fd[2])/2.0\n",
    "  fopt = lasso_admm(Xtrainhot, ytrain, lamopt, fmean1,fmean2,f, abscovinv,toladmm)\n",
    "  lossopt= 0.5*norm(Xtesthot*fopt[1].-ytest)^2\n",
    "  acc = cor(Xtesthot*fopt[1],ytest)\n",
    "\n",
    "  return lamopt,fopt,lossopt,acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lasso_admm (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Proximal ADMM lasso with line search\n",
    "function lasso_admm(Xtrainhot, ytrain, lam, theta, beta, f, abscovinv,tol; maxit=5000)\n",
    "  u = zero(theta)\n",
    "  grad = zero(theta)\n",
    "  lamw = lam*abscovinv # Regularization parameter times weights\n",
    "  g = NormL1(lamw) # Regularization function\n",
    "  c = 0.5\n",
    "  lr = 1.0\n",
    "  loss(theta) = 0.5*norm(Xtrainhot*theta-ytrain)^2 # Loss function for line search\n",
    "  for it = 1:maxit\n",
    "    # Line search\n",
    "    it % 8 == 1 && (grad = Xtrainhot'*(Xtrainhot*beta-ytrain))\n",
    "    while  it % 20 == 2 && loss(theta) > (loss(beta) + grad'*(-beta) + (1.0/(2.0*lr))*norm(-beta)^2)\n",
    "      lr = lr * c\n",
    "      #println(lr)\n",
    "    end\n",
    "    gam = lr\n",
    "    # ADMM perform f-update step\n",
    "    prox!(beta, f, theta - u, gam)\n",
    "    # ADMM perform g-update step\n",
    "    prox!(theta, g, beta + u, gam)\n",
    "    # Stopping criterion for ADMMM\n",
    "    if norm(beta-theta, Inf) <= tol*(1+norm(u, Inf))\n",
    "      break\n",
    "    end\n",
    "    # Dual update\n",
    "    u .+= beta - theta\n",
    "    #print(it)\n",
    "  end\n",
    "  return theta,beta,tol\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dong/GWAS/AtPolyDB/Silique_22.csv\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path = \"/Users/dong/GWAS/AtPolyDB/Silique_22.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76×214051 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  …  0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  2.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0  …  2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  2.0  0.0  2.0  0.0  2.0  2.0\n",
       " ⋮                        ⋮              ⋱       ⋮                        ⋮\n",
       " 0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  2.0  2.0  0.0  0.0  2.0  …  0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0  …  2.0  2.0  0.0  0.0  2.0  0.0  0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Silique_22.csv, and partition into train and test parts\n",
    "X = readdlm(data_file_path,',')\n",
    "ytot = (X[:,1].-mean(X[:,1])) # Center y to mean zero\n",
    "ytrain = ytot[1:76]\n",
    "Xtest= X[77:size(X)[1],2:size(X)[2]]\n",
    "ytest = ytot[77:size(X)[1]]\n",
    "Xtrain = X[1:76,2:size(X)[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding training data\n",
    "Xtrain0 = copy(Xtrain)\n",
    "Xtrain1 = copy(Xtrain)\n",
    "Xtrain2 = copy(Xtrain)\n",
    "Xtrain0[Xtrain0.==1] .= 2\n",
    "Xtrain0[Xtrain0.==0] .= 1\n",
    "Xtrain0[Xtrain0.==2] .= 0\n",
    "Xtrain1[Xtrain1.==2] .= 0\n",
    "Xtrain2[Xtrain2.==1] .= 0\n",
    "Xtrain2[Xtrain2.==2] .= 1\n",
    "Xtrainhot = hcat(Xtrain0,Xtrain1,Xtrain2)\n",
    "# Set unimportant allocations to zero\n",
    "Xtrain0 = 0\n",
    "Xtrain1 = 0\n",
    "Xtrain2 = 0\n",
    "Xtrain = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding test data\n",
    "Xtest0 = copy(Xtest)\n",
    "Xtest1 = copy(Xtest)\n",
    "Xtest2 = copy(Xtest)\n",
    "Xtest0[Xtest0.==1] .= 2\n",
    "Xtest0[Xtest0.==0] .= 1\n",
    "Xtest0[Xtest0.==2] .= 0\n",
    "Xtest1[Xtest1.==2] .= 0\n",
    "Xtest2[Xtest2.==1] .= 0\n",
    "Xtest2[Xtest2.==2] .= 1\n",
    "Xtesthot = hcat(Xtest0,Xtest1,Xtest2)\n",
    "# Set unimportant allocations to zero\n",
    "Xtest0 = 0\n",
    "Xtest1 = 0\n",
    "Xtest2 = 0\n",
    "Xtest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642153×1 Matrix{Float64}:\n",
       "  145.40816326530614\n",
       "  363.0573248407638\n",
       "  145.40816326530614\n",
       "  147.6683937823835\n",
       " 2850.000000000015\n",
       " 1075.4716981132058\n",
       " 2714.2857142857147\n",
       "  123.91304347826082\n",
       "   56.603773584905646\n",
       "  150.39577836411615\n",
       "  306.45161290322585\n",
       "   56.603773584905646\n",
       "  306.45161290322585\n",
       "    ⋮\n",
       "   87.15596330275226\n",
       "  303.1914893617024\n",
       "  155.31335149863753\n",
       "  123.37662337662337\n",
       " 4071.428571428539\n",
       "  105.94795539033458\n",
       "   65.66820276497694\n",
       "  123.37662337662337\n",
       " 1036.363636363638\n",
       "   44.91725768321513\n",
       "  255.60538116591945\n",
       "   87.55760368663596"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Factor for initial lower lambda\n",
    "alam = 0.0001\n",
    "# Factor for initial upper lambda\n",
    "blam = 1.0\n",
    "# Convergence factor for lambda in gss_opt\n",
    "tolgss = 0.01\n",
    "# Find lambda where all reg coeff are zero\n",
    "maxnorm = norm(Xtrainhot'*ytrain, Inf)\n",
    "# The least squares loss function\n",
    "f = LeastSquares(Xtrainhot, ytrain)\n",
    "# Inverse covariances to be used as weights in the adaptive lasso\n",
    "abscovinv = 1.0./abs.(cov(Xtrainhot,ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossc =0.29980000000000023\n",
      "lossd =0.29980000000000023\n",
      "lambdaa =0.00040399999999999925\n",
      "lambdab =4.039999999999992\n",
      "lambdac =1.5433923711818767\n",
      "lambdad =2.4970116288181154\n",
      "lambdac =2.4970116288181154\n",
      "lambdad =3.0863807423637537\n",
      "lambdac =3.0863807423637537\n",
      "lambdad =3.450630886454354\n",
      "lambdac =3.450630886454354\n",
      "lambdad =3.675749855909392\n",
      "lambdac =3.6757498559093915\n",
      "lambdad =3.8148810305449543\n",
      "lambdac =3.8148810305449543\n",
      "lambdad =3.9008688253644292\n",
      "lambdac =3.9008688253644292\n",
      "lambdad =3.954012205180517\n",
      "lambdac =3.954012205180517\n",
      "lambdad =3.986856620183904\n",
      "  3.323985 seconds (67.26 k allocations: 495.188 MiB, 6.88% gc time, 5.22% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.745315443227173, ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [-6.045965714518431e-6, -5.641138173029248e-6, -6.045965714518431e-6, 7.406858911540581e-6, -1.1083301087344566e-5, 9.569997130642882e-6, 5.858838606487282e-7, -6.882034233157697e-6, 3.708453269135603e-6, 8.90704241673923e-6  …  1.2544743364761857e-5, 1.6908124448322681e-6, -1.156182402331507e-6, -2.5091410004174364e-6, 1.0118541644565937e-6, 1.6908124448322681e-6, -2.6141015459363315e-6, -5.0649886049747295e-6, 4.585634206244471e-6, 5.145112734306068e-6], 0.0001), 0.29980000000000023, NaN)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run AUTALASSO with timing\n",
    "@time res = gss_opt(alam, blam, tolgss, Xtesthot, ytest,abscovinv,maxnorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dong/GWAS/Autalasso/\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"/Users/dong/GWAS/Autalasso/\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save regression coefficients, lambda, MSE and ACC to text files\n",
    "writedlm(joinpath(output_dir, \"outbeta_Silique22.txt\"), res[2][1])\n",
    "writedlm(joinpath(output_dir, \"outlambda_Silique22.txt\"), res[1])\n",
    "writedlm(joinpath(output_dir, \"outMSE_Silique22.txt\"), res[3]/length(ytest)*2)\n",
    "writedlm(joinpath(output_dir, \"outACC_Silique22.txt\"), res[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict observations for test data\n",
    "ytesthat = Xtesthot*res[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
