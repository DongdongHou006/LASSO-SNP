{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADMM adaptive lasso using ProximalOperators with line and golden section search\n",
    "# Automatic tuning of learning rate and regularization parameter\n",
    "# This code only only changes the ratio between test data and train data, and changes the input file\n",
    "# The original source code from https://github.com/patwa67/AUTALASSO\n",
    "\n",
    "using ProximalOperators\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gss_opt (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Golden section search to optimize lambda\n",
    "function gss_opt(alam, blam, tolgss, Xtesthot, ytest,abscovinv,maxnorm)\n",
    "  lama =alam*maxnorm # Lower lambda\n",
    "  lamb =blam*maxnorm # Higher lambda\n",
    "  gr = (sqrt(5.0) + 1.0) / 2.0 # Golden section ratio\n",
    "  toladmm = 1e-4 # Convergence tolerance for ADMM\n",
    "  fc = lasso_admm(Xtrainhot, ytrain, lama, zero(Xtrainhot[1,:]),zero(Xtrainhot[1,:]),f, abscovinv,toladmm)\n",
    "  lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "  fd = lasso_admm(Xtrainhot, ytrain, lamb, zero(Xtrainhot[1,:]),zero(Xtrainhot[1,:]),f, abscovinv,toladmm)\n",
    "  lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "  iter = 2\n",
    "  meanlam = zero(1.0:100.0)\n",
    "  #meanlam[iter] = (lama+lamb)/2\n",
    "  meanloss = zero(1.0:100.0)\n",
    "  #meanloss[1] = max(lossc,lossd)\n",
    "  #meanloss[iter] = (lossc+lossd)/2\n",
    "  lamc = lamb - (lamb - lama) / gr\n",
    "  lamd = lama + (lamb - lama) / gr\n",
    "  println(\"lossc =$lossc\")\n",
    "  println(\"lossd =$lossd\")\n",
    "  println(\"lambdaa =$lama\")\n",
    "  println(\"lambdab =$lamb\")\n",
    "  println(\"lambdac =$lamc\")\n",
    "  println(\"lambdad =$lamd\")\n",
    "  iter = 2\n",
    "  nodrun = 0\n",
    "  while abs(lamc - lamd)/((lamc + lamd)/2.0) > tolgss # Run GSS until convergence\n",
    "    iter = iter+1\n",
    "    if iter == 3\n",
    "    fc = lasso_admm(Xtrainhot, ytrain, lamc, fc[1],fc[2],f, abscovinv,toladmm)\n",
    "    lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "    fd = lasso_admm(Xtrainhot, ytrain, lamd, fd[1],fd[2],f, abscovinv,toladmm)\n",
    "    lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "    else\n",
    "    if nodrun==1\n",
    "    fc = lasso_admm(Xtrainhot, ytrain, lamc, fc[1],fc[2],f, abscovinv,toladmm)\n",
    "    lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "    else\n",
    "    fd = lasso_admm(Xtrainhot, ytrain, lamd, fd[1],fd[2],f, abscovinv,toladmm)\n",
    "    lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "    end\n",
    "    end\n",
    "    meanlam[iter] = (lamc+lamd)/2.0\n",
    "    meanloss[iter] = (lossc+lossd)/2.0\n",
    "    # Stop GSS if test MSE is increased two consecutive iterations\n",
    "    if (meanloss[iter] > meanloss[iter-1])&&(meanloss[iter-1] > meanloss[iter-2])\n",
    "      break\n",
    "    end\n",
    "    if lossc < lossd\n",
    "      lamb = lamd\n",
    "      fd=fc\n",
    "      lossd=lossc\n",
    "      nodrun=1\n",
    "    else\n",
    "      lama = lamc\n",
    "      fc=fd\n",
    "      lossc=lossd\n",
    "      nodrun=0\n",
    "    end\n",
    "    lamc = lamb - (lamb - lama) / gr\n",
    "    lamd = lama + (lamb - lama) / gr\n",
    "    #println(\"lossc =$lossc\")\n",
    "    #println(\"lossd =$lossd\")\n",
    "    println(\"lambdac =$lamc\")\n",
    "    println(\"lambdad =$lamd\")\n",
    "  end\n",
    "  # Final ADMM for optimized lambda\n",
    "  lamopt = meanlam[iter-2]\n",
    "  fmean1 = (fc[1]+fd[1])/2.0\n",
    "  fmean2 = (fc[2]+fd[2])/2.0\n",
    "  fopt = lasso_admm(Xtrainhot, ytrain, lamopt, fmean1,fmean2,f, abscovinv,toladmm)\n",
    "  lossopt= 0.5*norm(Xtesthot*fopt[1].-ytest)^2\n",
    "  acc = cor(Xtesthot*fopt[1],ytest)\n",
    "\n",
    "  return lamopt,fopt,lossopt,acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lasso_admm (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Proximal ADMM lasso with line search\n",
    "function lasso_admm(Xtrainhot, ytrain, lam, theta, beta, f, abscovinv,tol; maxit=5000)\n",
    "  u = zero(theta)\n",
    "  grad = zero(theta)\n",
    "  lamw = lam*abscovinv # Regularization parameter times weights\n",
    "  g = NormL1(lamw) # Regularization function\n",
    "  c = 0.5\n",
    "  lr = 1.0\n",
    "  loss(theta) = 0.5*norm(Xtrainhot*theta-ytrain)^2 # Loss function for line search\n",
    "  for it = 1:maxit\n",
    "    # Line search\n",
    "    it % 8 == 1 && (grad = Xtrainhot'*(Xtrainhot*beta-ytrain))\n",
    "    while  it % 20 == 2 && loss(theta) > (loss(beta) + grad'*(-beta) + (1.0/(2.0*lr))*norm(-beta)^2)\n",
    "      lr = lr * c\n",
    "      #println(lr)\n",
    "    end\n",
    "    gam = lr\n",
    "    # ADMM perform f-update step\n",
    "    prox!(beta, f, theta - u, gam)\n",
    "    # ADMM perform g-update step\n",
    "    prox!(theta, g, beta + u, gam)\n",
    "    # Stopping criterion for ADMMM\n",
    "    if norm(beta-theta, Inf) <= tol*(1+norm(u, Inf))\n",
    "      break\n",
    "    end\n",
    "    # Dual update\n",
    "    u .+= beta - theta\n",
    "    #print(it)\n",
    "  end\n",
    "  return theta,beta,tol\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dong/GWAS/AtPolyDB/Germ_22.csv\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path = \"/Users/dong/GWAS/AtPolyDB/Germ_22.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140×214051 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  2.0  2.0  0.0  0.0  2.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  2.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0  …  2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱       ⋮                        ⋮\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  2.0  0.0  0.0  0.0  2.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  2.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  0.0  0.0  2.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  2.0  2.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  2.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Germ_22.csv data, and partition into train and test parts\n",
    "X = readdlm(data_file_path,',')\n",
    "ytot = (X[:,1].-mean(X[:,1])) # Center y to mean zero\n",
    "ytrain = ytot[1:140]\n",
    "Xtest= X[141:size(X)[1],2:size(X)[2]]\n",
    "ytest = ytot[141:size(X)[1]]\n",
    "Xtrain = X[1:140,2:size(X)[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding training data\n",
    "Xtrain0 = copy(Xtrain)\n",
    "Xtrain1 = copy(Xtrain)\n",
    "Xtrain2 = copy(Xtrain)\n",
    "Xtrain0[Xtrain0.==1] .= 2\n",
    "Xtrain0[Xtrain0.==0] .= 1\n",
    "Xtrain0[Xtrain0.==2] .= 0\n",
    "Xtrain1[Xtrain1.==2] .= 0\n",
    "Xtrain2[Xtrain2.==1] .= 0\n",
    "Xtrain2[Xtrain2.==2] .= 1\n",
    "Xtrainhot = hcat(Xtrain0,Xtrain1,Xtrain2)\n",
    "# Set unimportant allocations to zero\n",
    "Xtrain0 = 0\n",
    "Xtrain1 = 0\n",
    "Xtrain2 = 0\n",
    "Xtrain = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding test data\n",
    "Xtest0 = copy(Xtest)\n",
    "Xtest1 = copy(Xtest)\n",
    "Xtest2 = copy(Xtest)\n",
    "Xtest0[Xtest0.==1] .= 2\n",
    "Xtest0[Xtest0.==0] .= 1\n",
    "Xtest0[Xtest0.==2] .= 0\n",
    "Xtest1[Xtest1.==2] .= 0\n",
    "Xtest2[Xtest2.==1] .= 0\n",
    "Xtest2[Xtest2.==2] .= 1\n",
    "Xtesthot = hcat(Xtest0,Xtest1,Xtest2)\n",
    "# Set unimportant allocations to zero\n",
    "Xtest0 = 0\n",
    "Xtest1 = 0\n",
    "Xtest2 = 0\n",
    "Xtest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642153×1 Matrix{Float64}:\n",
       "  79.42857142857142\n",
       " 555.999999999997\n",
       " 185.3333333333329\n",
       "  92.66666666666654\n",
       " 138.99999999999974\n",
       "  39.71428571428568\n",
       "  55.59999999999998\n",
       "  61.77777777777783\n",
       " 139.0\n",
       "  92.66666666666654\n",
       "  92.66666666666659\n",
       " 139.0\n",
       "  79.42857142857136\n",
       "   ⋮\n",
       "  46.33333333333341\n",
       " 277.99999999999926\n",
       " 111.2\n",
       " 138.99999999999991\n",
       " 556.0000000000007\n",
       "  46.3333333333333\n",
       "  61.77777777777763\n",
       "  69.5\n",
       " 111.2\n",
       "  42.76923076923073\n",
       " 185.3333333333341\n",
       " 556.0000000000015"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Factor for initial lower lambda\n",
    "alam = 0.0001\n",
    "# Factor for initial upper lambda\n",
    "blam = 1.0\n",
    "# Convergence factor for lambda in gss_opt\n",
    "tolgss = 0.01\n",
    "# Find lambda where all reg coeff are zero\n",
    "maxnorm = norm(Xtrainhot'*ytrain, Inf)\n",
    "# The least squares loss function\n",
    "f = LeastSquares(Xtrainhot, ytrain)\n",
    "# Inverse covariances to be used as weights in the adaptive lasso\n",
    "abscovinv = 1.0./abs.(cov(Xtrainhot,ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossc =10.896296891475343\n",
      "lossd =6.335104854926745\n",
      "lambdaa =0.0015372881355932223\n",
      "lambdab =15.372881355932222\n",
      "lambdac =5.872868269264837\n",
      "lambdad =9.501550374802978\n",
      "lambdac =9.501550374802978\n",
      "lambdad =11.74419925039408\n",
      "lambdac =11.744199250394082\n",
      "lambdad =13.130232480341117\n",
      "lambdac =13.13023248034112\n",
      "lambdad =13.986848125985185\n",
      "lambdac =13.986848125985187\n",
      "lambdad =14.516265710288156\n",
      "lambdac =14.516265710288156\n",
      "lambdad =14.843463771629253\n",
      "lambdac =14.843463771629253\n",
      "lambdad =15.045683294591125\n",
      "lambdac =15.045683294591123\n",
      "lambdad =15.170661832970351\n",
      " 81.752549 seconds (1.44 M allocations: 8.819 GiB, 2.33% gc time, 1.57% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14.251556918136671, ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [-5.9267935182808864e-6, 2.775040701640168e-6, -2.0650071581996394e-6, -3.1643218784353964e-6, -1.2003965977980412e-6, 1.0404117252556457e-5, -1.2885101740415486e-5, -6.037383720332042e-6, -3.127032573142194e-6, -2.824891434268157e-6  …  8.797335047563912e-6, 2.8518314048665735e-7, -1.1962537255428639e-6, 1.5120248109351262e-5, 3.791954850346985e-6, 3.189416092945241e-6, -1.981100244043877e-6, 7.969753093508081e-6, 1.6694917351013348e-6, 1.99881810135178e-6], 0.0001), 6.335104854926745, NaN)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run AUTALASSO with timing\n",
    "@time res = gss_opt(alam, blam, tolgss, Xtesthot, ytest,abscovinv,maxnorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dong/GWAS/Autalasso/\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"/Users/dong/GWAS/Autalasso/\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save regression coefficients, lambda, MSE and ACC to text files\n",
    "writedlm(joinpath(output_dir, \"outbeta_Germ22.txt\"), res[2][1])\n",
    "writedlm(joinpath(output_dir, \"outlambda_Germ22.txt\"), res[1])\n",
    "writedlm(joinpath(output_dir, \"outMSE_Germ22.txt\"), res[3]/length(ytest)*2)\n",
    "writedlm(joinpath(output_dir, \"outACC_Germ22.txt\"), res[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict observations for test data\n",
    "ytesthat = Xtesthot*res[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
