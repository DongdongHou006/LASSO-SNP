{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADMM adaptive lasso using ProximalOperators with line and golden section search\n",
    "# Automatic tuning of learning rate and regularization parameter\n",
    "# This code only only changes the ratio between test data and train data, and changes the input file\n",
    "# The original source code from https://github.com/patwa67/AUTALASSO\n",
    "\n",
    "using ProximalOperators\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gss_opt (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Golden section search to optimize lambda\n",
    "function gss_opt(alam, blam, tolgss, Xtesthot, ytest,abscovinv,maxnorm)\n",
    "  lama =alam*maxnorm # Lower lambda\n",
    "  lamb =blam*maxnorm # Higher lambda\n",
    "  gr = (sqrt(5.0) + 1.0) / 2.0 # Golden section ratio\n",
    "  toladmm = 1e-4 # Convergence tolerance for ADMM\n",
    "  fc = lasso_admm(Xtrainhot, ytrain, lama, zero(Xtrainhot[1,:]),zero(Xtrainhot[1,:]),f, abscovinv,toladmm)\n",
    "  lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "  fd = lasso_admm(Xtrainhot, ytrain, lamb, zero(Xtrainhot[1,:]),zero(Xtrainhot[1,:]),f, abscovinv,toladmm)\n",
    "  lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "  iter = 2\n",
    "  meanlam = zero(1.0:100.0)\n",
    "  #meanlam[iter] = (lama+lamb)/2\n",
    "  meanloss = zero(1.0:100.0)\n",
    "  #meanloss[1] = max(lossc,lossd)\n",
    "  #meanloss[iter] = (lossc+lossd)/2\n",
    "  lamc = lamb - (lamb - lama) / gr\n",
    "  lamd = lama + (lamb - lama) / gr\n",
    "  println(\"lossc =$lossc\")\n",
    "  println(\"lossd =$lossd\")\n",
    "  println(\"lambdaa =$lama\")\n",
    "  println(\"lambdab =$lamb\")\n",
    "  println(\"lambdac =$lamc\")\n",
    "  println(\"lambdad =$lamd\")\n",
    "  iter = 2\n",
    "  nodrun = 0\n",
    "  while abs(lamc - lamd)/((lamc + lamd)/2.0) > tolgss # Run GSS until convergence\n",
    "    iter = iter+1\n",
    "    if iter == 3\n",
    "    fc = lasso_admm(Xtrainhot, ytrain, lamc, fc[1],fc[2],f, abscovinv,toladmm)\n",
    "    lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "    fd = lasso_admm(Xtrainhot, ytrain, lamd, fd[1],fd[2],f, abscovinv,toladmm)\n",
    "    lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "    else\n",
    "    if nodrun==1\n",
    "    fc = lasso_admm(Xtrainhot, ytrain, lamc, fc[1],fc[2],f, abscovinv,toladmm)\n",
    "    lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "    else\n",
    "    fd = lasso_admm(Xtrainhot, ytrain, lamd, fd[1],fd[2],f, abscovinv,toladmm)\n",
    "    lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "    end\n",
    "    end\n",
    "    meanlam[iter] = (lamc+lamd)/2.0\n",
    "    meanloss[iter] = (lossc+lossd)/2.0\n",
    "    # Stop GSS if test MSE is increased two consecutive iterations\n",
    "    if (meanloss[iter] > meanloss[iter-1])&&(meanloss[iter-1] > meanloss[iter-2])\n",
    "      break\n",
    "    end\n",
    "    if lossc < lossd\n",
    "      lamb = lamd\n",
    "      fd=fc\n",
    "      lossd=lossc\n",
    "      nodrun=1\n",
    "    else\n",
    "      lama = lamc\n",
    "      fc=fd\n",
    "      lossc=lossd\n",
    "      nodrun=0\n",
    "    end\n",
    "    lamc = lamb - (lamb - lama) / gr\n",
    "    lamd = lama + (lamb - lama) / gr\n",
    "    #println(\"lossc =$lossc\")\n",
    "    #println(\"lossd =$lossd\")\n",
    "    println(\"lambdac =$lamc\")\n",
    "    println(\"lambdad =$lamd\")\n",
    "  end\n",
    "  # Final ADMM for optimized lambda\n",
    "  lamopt = meanlam[iter-2]\n",
    "  fmean1 = (fc[1]+fd[1])/2.0\n",
    "  fmean2 = (fc[2]+fd[2])/2.0\n",
    "  fopt = lasso_admm(Xtrainhot, ytrain, lamopt, fmean1,fmean2,f, abscovinv,toladmm)\n",
    "  lossopt= 0.5*norm(Xtesthot*fopt[1].-ytest)^2\n",
    "  acc = cor(Xtesthot*fopt[1],ytest)\n",
    "\n",
    "  return lamopt,fopt,lossopt,acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lasso_admm (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Proximal ADMM lasso with line search\n",
    "function lasso_admm(Xtrainhot, ytrain, lam, theta, beta, f, abscovinv,tol; maxit=5000)\n",
    "  u = zero(theta)\n",
    "  grad = zero(theta)\n",
    "  lamw = lam*abscovinv # Regularization parameter times weights\n",
    "  g = NormL1(lamw) # Regularization function\n",
    "  c = 0.5\n",
    "  lr = 1.0\n",
    "  loss(theta) = 0.5*norm(Xtrainhot*theta-ytrain)^2 # Loss function for line search\n",
    "  for it = 1:maxit\n",
    "    # Line search\n",
    "    it % 8 == 1 && (grad = Xtrainhot'*(Xtrainhot*beta-ytrain))\n",
    "    while  it % 20 == 2 && loss(theta) > (loss(beta) + grad'*(-beta) + (1.0/(2.0*lr))*norm(-beta)^2)\n",
    "      lr = lr * c\n",
    "      #println(lr)\n",
    "    end\n",
    "    gam = lr\n",
    "    # ADMM perform f-update step\n",
    "    prox!(beta, f, theta - u, gam)\n",
    "    # ADMM perform g-update step\n",
    "    prox!(theta, g, beta + u, gam)\n",
    "    # Stopping criterion for ADMMM\n",
    "    if norm(beta-theta, Inf) <= tol*(1+norm(u, Inf))\n",
    "      break\n",
    "    end\n",
    "    # Dual update\n",
    "    u .+= beta - theta\n",
    "    #print(it)\n",
    "  end\n",
    "  return theta,beta,tol\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dong/GWAS/AtPolyDB/Width_22.csv\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path = \"/Users/dong/GWAS/AtPolyDB/Width_22.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150×214051 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  2.0  2.0  0.0  0.0  2.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  2.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0  …  2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱       ⋮                        ⋮\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 2.0  0.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  2.0  0.0  0.0  0.0  2.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0     0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  2.0  2.0  0.0  0.0  2.0  …  0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Width_22.csv, and partition into train and test parts\n",
    "X = readdlm(data_file_path,',')\n",
    "ytot = (X[:,1].-mean(X[:,1])) # Center y to mean zero\n",
    "ytrain = ytot[1:150]\n",
    "Xtest= X[151:size(X)[1],2:size(X)[2]]\n",
    "ytest = ytot[151:size(X)[1]]\n",
    "Xtrain = X[1:150,2:size(X)[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding training data\n",
    "Xtrain0 = copy(Xtrain)\n",
    "Xtrain1 = copy(Xtrain)\n",
    "Xtrain2 = copy(Xtrain)\n",
    "Xtrain0[Xtrain0.==1] .= 2\n",
    "Xtrain0[Xtrain0.==0] .= 1\n",
    "Xtrain0[Xtrain0.==2] .= 0\n",
    "Xtrain1[Xtrain1.==2] .= 0\n",
    "Xtrain2[Xtrain2.==1] .= 0\n",
    "Xtrain2[Xtrain2.==2] .= 1\n",
    "Xtrainhot = hcat(Xtrain0,Xtrain1,Xtrain2)\n",
    "# Set unimportant allocations to zero\n",
    "Xtrain0 = 0\n",
    "Xtrain1 = 0\n",
    "Xtrain2 = 0\n",
    "Xtrain = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding test data\n",
    "Xtest0 = copy(Xtest)\n",
    "Xtest1 = copy(Xtest)\n",
    "Xtest2 = copy(Xtest)\n",
    "Xtest0[Xtest0.==1] .= 2\n",
    "Xtest0[Xtest0.==0] .= 1\n",
    "Xtest0[Xtest0.==2] .= 0\n",
    "Xtest1[Xtest1.==2] .= 0\n",
    "Xtest2[Xtest2.==1] .= 0\n",
    "Xtest2[Xtest2.==2] .= 1\n",
    "Xtesthot = hcat(Xtest0,Xtest1,Xtest2)\n",
    "# Set unimportant allocations to zero\n",
    "Xtest0 = 0\n",
    "Xtest1 = 0\n",
    "Xtest2 = 0\n",
    "Xtest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642153×1 Matrix{Float64}:\n",
       "   74.99999999999997\n",
       "  256.89655172413757\n",
       "   84.819734345351\n",
       "   23.041237113402072\n",
       "  120.81081081081071\n",
       "   11.948676824378506\n",
       "   54.05078597339782\n",
       "  161.3718411552353\n",
       "   31.128133704735372\n",
       "   21.084905660377363\n",
       " 1090.2439024390208\n",
       "  519.7674418604649\n",
       "   57.603092783505154\n",
       "    ⋮\n",
       "  111.19402985074618\n",
       "   61.48555708390638\n",
       "   22.117763483424042\n",
       "   11.601349597716062\n",
       "  451.51515151514883\n",
       "   35.05882352941176\n",
       "   46.46569646569648\n",
       "   10.388101324657214\n",
       "   30.763936682725422\n",
       "   20.438957475994513\n",
       "   16.604754829123312\n",
       "   19.88434163701066"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Factor for initial lower lambda\n",
    "alam = 0.0001\n",
    "# Factor for initial upper lambda\n",
    "blam = 1.0\n",
    "# Convergence factor for lambda in gss_opt\n",
    "tolgss = 0.01\n",
    "# Find lambda where all reg coeff are zero\n",
    "maxnorm = norm(Xtrainhot'*ytrain, Inf)\n",
    "# The least squares loss function\n",
    "f = LeastSquares(Xtrainhot, ytrain)\n",
    "# Inverse covariances to be used as weights in the adaptive lasso\n",
    "abscovinv = 1.0./abs.(cov(Xtrainhot,ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossc =48.86055178143158\n",
      "lossd =49.39170204081634\n",
      "lambdaa =0.006593999999999991\n",
      "lambdab =65.93999999999991\n",
      "lambdac =25.190914097953723\n",
      "lambdad =40.75567990204619\n",
      "lambdac =40.7556799020462\n",
      "lambdad =50.37523419590744\n",
      "lambdac =34.810468391814965\n",
      "lambdad =40.7556799020462\n",
      "lambdac =31.136125608184962\n",
      "lambdad =34.81046839181496\n",
      "lambdac =28.86525688158372\n",
      "lambdad =31.136125608184962\n",
      "lambdac =27.461782824554962\n",
      "lambdad =28.865256881583722\n",
      "lambdac =26.594388154982482\n",
      "lambdad =27.461782824554962\n",
      "lambdac =27.461782824554962\n",
      "lambdad =27.997862212011242\n",
      "lambdac =27.130467542438762\n",
      "lambdad =27.461782824554962\n",
      "134.929756 seconds (9.56 k allocations: 15.968 GiB, 2.37% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27.02808548976872, ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.611078702017026e-7, 4.7204683493285533e-7, 6.326004901743257e-7, 7.325009166534314e-7, 6.853675032286114e-7, 1.263060048117999e-7, 5.443274508242413e-7, 7.354995049485514e-7, 6.574592242769225e-7, 7.28967577894458e-7  …  1.9871509276482883e-8, -6.854315619814612e-8, 2.5216649999643645e-8, 7.230285554401031e-9, 3.604375531366706e-7, -1.8133799440736846e-8, 1.355402846207242e-7, 3.3307180988701455e-7, 6.717901894623055e-8, 1.955891842386973e-7], 0.0001), 49.326934589577675, 0.1306662342205459)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run AUTALASSO with timing\n",
    "@time res = gss_opt(alam, blam, tolgss, Xtesthot, ytest,abscovinv,maxnorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dong/GWAS/Autalasso/\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"/Users/dong/GWAS/Autalasso/\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save regression coefficients, lambda, MSE and ACC to text files\n",
    "writedlm(joinpath(output_dir, \"outbeta_Width22.txt\"), res[2][1])\n",
    "writedlm(joinpath(output_dir, \"outlambda_Width22.txt\"), res[1])\n",
    "writedlm(joinpath(output_dir, \"outMSE_Width22.txt\"), res[3]/length(ytest)*2)\n",
    "writedlm(joinpath(output_dir, \"outACC_Width22.txt\"), res[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Vector{Float64}:\n",
       "  0.013263438840265524\n",
       " -0.011337293313052136\n",
       " -0.0040583425057655505\n",
       "  0.010429743413118775\n",
       "  0.01739106713890421\n",
       "  0.01739106713890421\n",
       "  0.01739106713890421\n",
       " -0.014170988740198886\n",
       " -0.007209665014413448\n",
       "  0.010429743413118775\n",
       " -0.004375969587266699\n",
       "  0.01739106713890421\n",
       " -0.004375969587266699\n",
       "  0.008863856703740732\n",
       " -0.007209665014413448\n",
       " -0.007209665014413448\n",
       " -0.007209665014413448\n",
       " -0.014170988740198886\n",
       " -0.011337293313052136\n",
       "  0.013263438840265524\n",
       " -0.014170988740198886\n",
       "  0.01739106713890421\n",
       " -0.011337293313052136\n",
       " -0.004375969587266699\n",
       " -0.011337293313052136"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict observations for test data\n",
    "ytesthat = Xtesthot*res[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
