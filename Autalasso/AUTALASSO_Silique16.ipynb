{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADMM adaptive lasso using ProximalOperators with line and golden section search\n",
    "# Automatic tuning of learning rate and regularization parameter\n",
    "# This code only only changes the ratio between test data and train data, and changes the input file\n",
    "# The original source code from https://github.com/patwa67/AUTALASSO\n",
    "\n",
    "using ProximalOperators\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gss_opt (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Golden section search to optimize lambda\n",
    "function gss_opt(alam, blam, tolgss, Xtesthot, ytest,abscovinv,maxnorm)\n",
    "  lama =alam*maxnorm # Lower lambda\n",
    "  lamb =blam*maxnorm # Higher lambda\n",
    "  gr = (sqrt(5.0) + 1.0) / 2.0 # Golden section ratio\n",
    "  toladmm = 1e-4 # Convergence tolerance for ADMM\n",
    "  fc = lasso_admm(Xtrainhot, ytrain, lama, zero(Xtrainhot[1,:]),zero(Xtrainhot[1,:]),f, abscovinv,toladmm)\n",
    "  lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "  fd = lasso_admm(Xtrainhot, ytrain, lamb, zero(Xtrainhot[1,:]),zero(Xtrainhot[1,:]),f, abscovinv,toladmm)\n",
    "  lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "  iter = 2\n",
    "  meanlam = zero(1.0:100.0)\n",
    "  #meanlam[iter] = (lama+lamb)/2\n",
    "  meanloss = zero(1.0:100.0)\n",
    "  #meanloss[1] = max(lossc,lossd)\n",
    "  #meanloss[iter] = (lossc+lossd)/2\n",
    "  lamc = lamb - (lamb - lama) / gr\n",
    "  lamd = lama + (lamb - lama) / gr\n",
    "  println(\"lossc =$lossc\")\n",
    "  println(\"lossd =$lossd\")\n",
    "  println(\"lambdaa =$lama\")\n",
    "  println(\"lambdab =$lamb\")\n",
    "  println(\"lambdac =$lamc\")\n",
    "  println(\"lambdad =$lamd\")\n",
    "  iter = 2\n",
    "  nodrun = 0\n",
    "  while abs(lamc - lamd)/((lamc + lamd)/2.0) > tolgss # Run GSS until convergence\n",
    "    iter = iter+1\n",
    "    if iter == 3\n",
    "    fc = lasso_admm(Xtrainhot, ytrain, lamc, fc[1],fc[2],f, abscovinv,toladmm)\n",
    "    lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "    fd = lasso_admm(Xtrainhot, ytrain, lamd, fd[1],fd[2],f, abscovinv,toladmm)\n",
    "    lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "    else\n",
    "    if nodrun==1\n",
    "    fc = lasso_admm(Xtrainhot, ytrain, lamc, fc[1],fc[2],f, abscovinv,toladmm)\n",
    "    lossc= 0.5*norm(Xtesthot*fc[1].-ytest)^2 # Test error for initial lower lambda\n",
    "    else\n",
    "    fd = lasso_admm(Xtrainhot, ytrain, lamd, fd[1],fd[2],f, abscovinv,toladmm)\n",
    "    lossd= 0.5*norm(Xtesthot*fd[1].-ytest)^2 # Test error for initial higher lambda\n",
    "    end\n",
    "    end\n",
    "    meanlam[iter] = (lamc+lamd)/2.0\n",
    "    meanloss[iter] = (lossc+lossd)/2.0\n",
    "    # Stop GSS if test MSE is increased two consecutive iterations\n",
    "    if (meanloss[iter] > meanloss[iter-1])&&(meanloss[iter-1] > meanloss[iter-2])\n",
    "      break\n",
    "    end\n",
    "    if lossc < lossd\n",
    "      lamb = lamd\n",
    "      fd=fc\n",
    "      lossd=lossc\n",
    "      nodrun=1\n",
    "    else\n",
    "      lama = lamc\n",
    "      fc=fd\n",
    "      lossc=lossd\n",
    "      nodrun=0\n",
    "    end\n",
    "    lamc = lamb - (lamb - lama) / gr\n",
    "    lamd = lama + (lamb - lama) / gr\n",
    "    #println(\"lossc =$lossc\")\n",
    "    #println(\"lossd =$lossd\")\n",
    "    println(\"lambdac =$lamc\")\n",
    "    println(\"lambdad =$lamd\")\n",
    "  end\n",
    "  # Final ADMM for optimized lambda\n",
    "  lamopt = meanlam[iter-2]\n",
    "  fmean1 = (fc[1]+fd[1])/2.0\n",
    "  fmean2 = (fc[2]+fd[2])/2.0\n",
    "  fopt = lasso_admm(Xtrainhot, ytrain, lamopt, fmean1,fmean2,f, abscovinv,toladmm)\n",
    "  lossopt= 0.5*norm(Xtesthot*fopt[1].-ytest)^2\n",
    "  acc = cor(Xtesthot*fopt[1],ytest)\n",
    "\n",
    "  return lamopt,fopt,lossopt,acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lasso_admm (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Proximal ADMM lasso with line search\n",
    "function lasso_admm(Xtrainhot, ytrain, lam, theta, beta, f, abscovinv,tol; maxit=5000)\n",
    "  u = zero(theta)\n",
    "  grad = zero(theta)\n",
    "  lamw = lam*abscovinv # Regularization parameter times weights\n",
    "  g = NormL1(lamw) # Regularization function\n",
    "  c = 0.5\n",
    "  lr = 1.0\n",
    "  loss(theta) = 0.5*norm(Xtrainhot*theta-ytrain)^2 # Loss function for line search\n",
    "  for it = 1:maxit\n",
    "    # Line search\n",
    "    it % 8 == 1 && (grad = Xtrainhot'*(Xtrainhot*beta-ytrain))\n",
    "    while  it % 20 == 2 && loss(theta) > (loss(beta) + grad'*(-beta) + (1.0/(2.0*lr))*norm(-beta)^2)\n",
    "      lr = lr * c\n",
    "      #println(lr)\n",
    "    end\n",
    "    gam = lr\n",
    "    # ADMM perform f-update step\n",
    "    prox!(beta, f, theta - u, gam)\n",
    "    # ADMM perform g-update step\n",
    "    prox!(theta, g, beta + u, gam)\n",
    "    # Stopping criterion for ADMMM\n",
    "    if norm(beta-theta, Inf) <= tol*(1+norm(u, Inf))\n",
    "      break\n",
    "    end\n",
    "    # Dual update\n",
    "    u .+= beta - theta\n",
    "    #print(it)\n",
    "  end\n",
    "  return theta,beta,tol\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dong/GWAS/AtPolyDB/Silique_16.csv\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path = \"/Users/dong/GWAS/AtPolyDB/Silique_16.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76×214051 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  …  0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  2.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0  …  2.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0     0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  2.0  0.0  2.0  0.0  2.0  2.0\n",
       " ⋮                        ⋮              ⋱       ⋮                        ⋮\n",
       " 0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  2.0  2.0  0.0  0.0  2.0  …  0.0  2.0  2.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  2.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  2.0  0.0  0.0  2.0  0.0  0.0\n",
       " 2.0  2.0  2.0  0.0  0.0  0.0  0.0  2.0  …  2.0  2.0  0.0  0.0  2.0  0.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Silique_16.csv, and partition into train and test parts\n",
    "X = readdlm(data_file_path,',')\n",
    "ytot = (X[:,1].-mean(X[:,1])) # Center y to mean zero\n",
    "ytrain = ytot[1:76]\n",
    "Xtest= X[77:size(X)[1],2:size(X)[2]]\n",
    "ytest = ytot[77:size(X)[1]]\n",
    "Xtrain = X[1:76,2:size(X)[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding training data\n",
    "Xtrain0 = copy(Xtrain)\n",
    "Xtrain1 = copy(Xtrain)\n",
    "Xtrain2 = copy(Xtrain)\n",
    "Xtrain0[Xtrain0.==1] .= 2\n",
    "Xtrain0[Xtrain0.==0] .= 1\n",
    "Xtrain0[Xtrain0.==2] .= 0\n",
    "Xtrain1[Xtrain1.==2] .= 0\n",
    "Xtrain2[Xtrain2.==1] .= 0\n",
    "Xtrain2[Xtrain2.==2] .= 1\n",
    "Xtrainhot = hcat(Xtrain0,Xtrain1,Xtrain2)\n",
    "# Set unimportant allocations to zero\n",
    "Xtrain0 = 0\n",
    "Xtrain1 = 0\n",
    "Xtrain2 = 0\n",
    "Xtrain = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding test data\n",
    "Xtest0 = copy(Xtest)\n",
    "Xtest1 = copy(Xtest)\n",
    "Xtest2 = copy(Xtest)\n",
    "Xtest0[Xtest0.==1] .= 2\n",
    "Xtest0[Xtest0.==0] .= 1\n",
    "Xtest0[Xtest0.==2] .= 0\n",
    "Xtest1[Xtest1.==2] .= 0\n",
    "Xtest2[Xtest2.==1] .= 0\n",
    "Xtest2[Xtest2.==2] .= 1\n",
    "Xtesthot = hcat(Xtest0,Xtest1,Xtest2)\n",
    "# Set unimportant allocations to zero\n",
    "Xtest0 = 0\n",
    "Xtest1 = 0\n",
    "Xtest2 = 0\n",
    "Xtest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642153×1 Matrix{Float64}:\n",
       "   91.93548387096774\n",
       "   92.98531810766718\n",
       "   91.93548387096774\n",
       "  191.27516778523483\n",
       "   85.84337349397589\n",
       "  141.43920595533507\n",
       " 2714.285714285719\n",
       "  245.68965517241375\n",
       "  600.0000000000007\n",
       "  740.2597402597394\n",
       "  211.11111111111103\n",
       "  600.0000000000007\n",
       "  211.11111111111103\n",
       "    ⋮\n",
       " 1239.1304347826017\n",
       "   65.36697247706418\n",
       "  410.07194244604307\n",
       "  814.2857142857157\n",
       "  196.55172413793096\n",
       "  256.7567567567567\n",
       " 1295.4545454545498\n",
       "  814.2857142857157\n",
       "  275.3623188405796\n",
       "  118.99791231732779\n",
       "   62.84454244762953\n",
       "   88.92355694227771"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Factor for initial lower lambda\n",
    "alam = 0.0001\n",
    "# Factor for initial upper lambda\n",
    "blam = 1.0\n",
    "# Convergence factor for lambda in gss_opt\n",
    "tolgss = 0.01\n",
    "# Find lambda where all reg coeff are zero\n",
    "maxnorm = norm(Xtrainhot'*ytrain, Inf)\n",
    "# The least squares loss function\n",
    "f = LeastSquares(Xtrainhot, ytrain)\n",
    "# Inverse covariances to be used as weights in the adaptive lasso\n",
    "abscovinv = 1.0./abs.(cov(Xtrainhot,ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossc =0.1769368421052631\n",
      "lossd =0.1769368421052631\n",
      "lambdaa =0.0003688421052631583\n",
      "lambdab =3.688421052631583\n",
      "lambdac =1.4090794342421349\n",
      "lambdad =2.2797104604947114\n",
      "lambdac =2.279710460494712\n",
      "lambdad =2.817790026379006\n",
      "lambdac =2.817790026379006\n",
      "lambdad =3.1503414867472888\n",
      "lambdac =3.1503414867472888\n",
      "lambdad =3.355869592263301\n",
      "lambdac =3.355869592263301\n",
      "lambdad =3.482892947115571\n",
      "lambdac =3.482892947115571\n",
      "lambdad =3.561397697779313\n",
      "lambdac =3.561397697779313\n",
      "lambdad =3.609916301967841\n",
      "lambdac =3.609916301967841\n",
      "lambdad =3.639902448443055\n",
      "  3.777079 seconds (1.43 M allocations: 586.124 MiB, 33.22% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.4193812696894357, ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [-1.556464340782271e-5, -1.69124077244176e-5, -1.556464340782271e-5, 1.0156772245251133e-5, 1.8216660362835313e-5, 6.764334873343714e-6, 1.1104674841888595e-6, -3.220334643727618e-6, -6.58922112828364e-6, 2.6968264231763683e-6  …  -2.8960097557817477e-6, 2.3875042930998625e-6, 4.50229847159811e-6, -2.3837855992470125e-6, 3.7396410750289988e-6, 2.3875042930998625e-6, 2.7213809125070654e-6, -3.798971855206723e-6, -4.93182471705822e-6, 3.8146019367690798e-6], 0.0001), 0.1769368421052631, NaN)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run AUTALASSO with timing\n",
    "@time res = gss_opt(alam, blam, tolgss, Xtesthot, ytest,abscovinv,maxnorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dong/GWAS/Autalasso/\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"/Users/dong/GWAS/Autalasso/\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save regression coefficients, lambda, MSE and ACC to text files\n",
    "#writedlm(\"outbetaQTLMAS.txt\", res[2][1])\n",
    "#writedlm(\"outlambdaQTLMAS.txt\", res[1])\n",
    "#writedlm(\"outMSEQTLMAS.txt\", res[3]/length(ytest)*2)\n",
    "#writedlm(\"outACCQTLMAS.txt\", res[4])\n",
    "\n",
    "writedlm(joinpath(output_dir, \"outbeta_Silique16.txt\"), res[2][1])\n",
    "writedlm(joinpath(output_dir, \"outlambda_Silique16.txt\"), res[1])\n",
    "writedlm(joinpath(output_dir, \"outMSE_Silique16.txt\"), res[3]/length(ytest)*2)\n",
    "writedlm(joinpath(output_dir, \"outACC_Silique16.txt\"), res[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict observations for test data\n",
    "ytesthat = Xtesthot*res[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
